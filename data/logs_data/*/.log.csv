Starting training ...
Starting Compression ...
Using TensorFlow backend.
Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File "/opt/conda/lib/python3.6/imp.py", line 243, in load_module
    return load_dynamic(name, filename, file)
  File "/opt/conda/lib/python3.6/imp.py", line 343, in load_dynamic
    return _load(spec)
ImportError: libcuda.so.1: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "compressor.py", line 20, in <module>
    import keras
  File "/src/keras/__init__.py", line 3, in <module>
    from . import utils
  File "/src/keras/utils/__init__.py", line 6, in <module>
    from . import conv_utils
  File "/src/keras/utils/conv_utils.py", line 9, in <module>
    from .. import backend as K
  File "/src/keras/backend/__init__.py", line 89, in <module>
    from .tensorflow_backend import *
  File "/src/keras/backend/tensorflow_backend.py", line 5, in <module>
    import tensorflow as tf
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/__init__.py", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/__init__.py", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File "/opt/conda/lib/python3.6/imp.py", line 243, in load_module
    return load_dynamic(name, filename, file)
  File "/opt/conda/lib/python3.6/imp.py", line 343, in load_dynamic
    return _load(spec)
ImportError: libcuda.so.1: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
Command exited with non-zero status 1
	Command being timed: "python compressor.py -data ../data/processed_files/*.npy -data_params ../data/processed_files/*.param.json -model ../data/trained_models/*/.hdf5 -model_name -output ../data/compressed/*/.compressed -batch_size 1000"
	User time (seconds): 0.53
	System time (seconds): 0.09
	Percent of CPU this job got: 86%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.71
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 87408
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 0
	Minor (reclaiming a frame) page faults: 28056
	Voluntary context switches: 228
	Involuntary context switches: 71
	Swaps: 0
	File system inputs: 40
	File system outputs: 0
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 1
Using TensorFlow backend.
Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File "/opt/conda/lib/python3.6/imp.py", line 243, in load_module
    return load_dynamic(name, filename, file)
  File "/opt/conda/lib/python3.6/imp.py", line 343, in load_dynamic
    return _load(spec)
ImportError: libcuda.so.1: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "decompressor.py", line 20, in <module>
    import keras
  File "/src/keras/__init__.py", line 3, in <module>
    from . import utils
  File "/src/keras/utils/__init__.py", line 6, in <module>
    from . import conv_utils
  File "/src/keras/utils/conv_utils.py", line 9, in <module>
    from .. import backend as K
  File "/src/keras/backend/__init__.py", line 89, in <module>
    from .tensorflow_backend import *
  File "/src/keras/backend/tensorflow_backend.py", line 5, in <module>
    import tensorflow as tf
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/__init__.py", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/__init__.py", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File "/opt/conda/lib/python3.6/imp.py", line 243, in load_module
    return load_dynamic(name, filename, file)
  File "/opt/conda/lib/python3.6/imp.py", line 343, in load_dynamic
    return _load(spec)
ImportError: libcuda.so.1: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
Command exited with non-zero status 1
	Command being timed: "python decompressor.py -output ../data/compressed/*/.reconstructed.txt -model ../data/trained_models/*/.hdf5 -model_name -input_file_prefix ../data/compressed/*/.compressed -batch_size 1000"
	User time (seconds): 0.52
	System time (seconds): 0.10
	Percent of CPU this job got: 88%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.70
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 87276
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 0
	Minor (reclaiming a frame) page faults: 27965
	Voluntary context switches: 228
	Involuntary context switches: 30
	Swaps: 0
	File system inputs: 56
	File system outputs: 0
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 1
Starting training ...
Starting Compression ...
Using TensorFlow backend.
usage: compressor.py [-h] [-model MODEL_WEIGHTS_FILE] [-model_name MODEL_NAME]
                     [-batch_size BATCH_SIZE] [-data SEQUENCE_NPY_FILE]
                     [-data_params PARAMS_FILE] [-output OUTPUT_FILE_PREFIX]
compressor.py: error: argument -model_name: expected one argument
Command exited with non-zero status 2
	Command being timed: "python compressor.py -data ../data/processed_files/*.npy -data_params ../data/processed_files/*.param.json -model ../data/trained_models/*/.hdf5 -model_name -output ../data/compressed/*/.compressed -batch_size 1000"
	User time (seconds): 1.54
	System time (seconds): 0.17
	Percent of CPU this job got: 86%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:01.98
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 226876
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 0
	Minor (reclaiming a frame) page faults: 64879
	Voluntary context switches: 864
	Involuntary context switches: 90
	Swaps: 0
	File system inputs: 120
	File system outputs: 0
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 2
Using TensorFlow backend.
usage: decompressor.py [-h] [-model MODEL_WEIGHTS_FILE]
                       [-model_name MODEL_NAME] [-batch_size BATCH_SIZE]
                       [-output OUTPUT_FILE_NAME]
                       [-input_file_prefix INPUT_FILE_PREFIX]
decompressor.py: error: argument -model_name: expected one argument
Command exited with non-zero status 2
	Command being timed: "python decompressor.py -output ../data/compressed/*/.reconstructed.txt -model ../data/trained_models/*/.hdf5 -model_name -input_file_prefix ../data/compressed/*/.compressed -batch_size 1000"
	User time (seconds): 1.54
	System time (seconds): 0.18
	Percent of CPU this job got: 87%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:01.97
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 226508
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 0
	Minor (reclaiming a frame) page faults: 64916
	Voluntary context switches: 848
	Involuntary context switches: 1050
	Swaps: 0
	File system inputs: 88
	File system outputs: 0
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 2
